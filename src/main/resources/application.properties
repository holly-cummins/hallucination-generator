# Chat model
quarkus.langchain4j.ollama.chat-model.model-id=llama3.2:3b
quarkus.langchain4j.ollama.chat-model.temperature=2 
quarkus.langchain4j.ollama.chat-model.log-responses=true
quarkus.langchain4j.ollama.validator.chat-model.model-id=gemma3:4b
quarkus.langchain4j.ollama.validator.chat-model.temperature=0 
quarkus.langchain4j.ollama.validator.chat-model.log-responses=true
quarkus.langchain4j.timeout=60s 
quarkus.langchain4j.ollama.chat-model.base-url=http://localhost:11434/v1/

