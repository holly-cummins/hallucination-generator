
# Chat model
quarkus.langchain4j.ollama.chat-model.model-id=smollm2:360m
quarkus.langchain4j.ollama.chat-model.model-name=smollm2:360m
quarkus.langchain4j.ollama.chat-model.temperature=1 
quarkus.langchain4j.ollama.chat-model.log-responses=true

quarkus.langchain4j.ollama.validator.chat-model.model-id=gemma3:1b
quarkus.langchain4j.ollama.validator.chat-model.model-name=gemma3:1b
quarkus.langchain4j.ollama.validator.chat-model.temperature=1 
quarkus.langchain4j.ollama.validator.chat-model.log-responses=true

quarkus.langchain4j.timeout=60s 

#quarkus.langchain4j.ollama.chat-model.base-url=http://localhost:11434

# Embedding model
#quarkus.langchain4j.ollama.embedding-model.model-name=snowflake-arctic-embed:latest

# TODO embedding needed?
